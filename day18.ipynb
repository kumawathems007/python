{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import nltk\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "hog=cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "vid=cv2.VideoCapture(index=0)\n",
    "while True:\n",
    "    ack, img=vid.read()\n",
    "    if ack:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        people, weights = hog.detectMultiScale(gray_img, winStride=(15,15),)\n",
    "        for x,y,w,h in people:\n",
    "            cv2.rectangle(img, pt1=(x,y),pt2=(x+w,y+h), color=(0,0,255),thickness=5,)\n",
    "        sleep(0.1)\n",
    "        cv2.imshow('Preview',img)\n",
    "        if cv2.waitKey(delay=1) == ord('x'):\n",
    "            break \n",
    "cv2.destroyAllWindows()\n",
    "vid.release()           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "tts = pyttsx3.init()\n",
    "tts.setProperty('rate',100)\n",
    "tts.say('Hello! I am speaking for you from your computer')\n",
    "tts.runAndWait()\n",
    "tts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "hello\n",
      "You said: hello\n",
      "Speak:\n",
      "yah last wala hai jo\n",
      "You said: yah last wala hai jo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\Desktop\\python AIDP\\__pycache__\\day18.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m flag \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m mic:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSpeak:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         audio \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mlisten(mic, phrase_time_limit\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:189\u001b[0m, in \u001b[0;36mMicrophone.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[0;32m    188\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m    190\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:207\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaudio_stream\u001b[39m.\u001b[39mstop_stream()\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:451\u001b[0m, in \u001b[0;36mPyAudio.Stream.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    450\u001b[0m     \u001b[39m\"\"\"Closes the stream.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     pa\u001b[39m.\u001b[39;49mclose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream)\n\u001b[0;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_running \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent\u001b[39m.\u001b[39m_remove_stream(\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings ;\n",
    "warnings.filterwarnings('ignore')\n",
    "import speech_recognition as sr\n",
    "import webbrowser as web\n",
    "rec = sr.Recognizer()\n",
    "flag = False\n",
    "while True:\n",
    "    with sr.Microphone() as mic:\n",
    "        print('Speak:')\n",
    "        audio = rec.listen(mic, phrase_time_limit=3, timeout=5)\n",
    "        try:\n",
    "            text=rec.recognize_google(audio).lower()\n",
    "            print(text)\n",
    "            if flag == True:\n",
    "                if 'search' in text:\n",
    "                    item=text.split('search')[-1].strip()\n",
    "                    flipkart_url = 'https://flipkart.com/search?q='\n",
    "                    amazon_url = 'https://amazon.in/s?k='\n",
    "                    web.open_new(flipkart_url + item)\n",
    "                    web.open_new_tab(amazon_url + item)\n",
    "                flag = False\n",
    "            if 'hey google' in text:\n",
    "                flag=True\n",
    "            elif 'mar ja' in text:\n",
    "                break\n",
    "            if flag == False:\n",
    "               print('You said:',text)\n",
    "               tts.say(text)\n",
    "               tts.runAndWait()\n",
    "        except Exception as err:\n",
    "                print(err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chat.util import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=r'(.*)your name (.*)company(.*)'\n",
    "a1=['my name is chatchat','I am chatchat']\n",
    "q2=r'kya aaj kuch achh hoga'\n",
    "a2=['haan','mujhe kya pata','meai kyo batau']\n",
    "qa_pair=[[q1,a1],[q2,a2],]\n",
    "cb=Chat(qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    }
   ],
   "source": [
    "ques = input('enter ques:').lower()\n",
    "resp = cb.respond(ques),\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "iphone 14 search\n",
      "Speak:\n",
      "hey google\n",
      "Speak:\n",
      "iphone 14 search on the amazon\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "assistant\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "flipkart\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "are yah chali rakesh ko band kaise karna hai\n",
      "Speak:\n",
      "\n",
      "Speak:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\Desktop\\python AIDP\\__pycache__\\day18.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m mic:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSpeak:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     audio \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39;49mlisten(mic,phrase_time_limit\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,timeout\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/python%20AIDP/__pycache__/day18.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m        text \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mrecognize_google(audio)\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "   from nltk.chat.util import Chat\n",
    "   import speech_recognition as sr\n",
    "   import pyttsx3\n",
    "    \n",
    "   q1 = r'(.*)your name (.*)company(.*)'\n",
    "   a1 = ['my name is chatchat','I am chatchat']\n",
    "   q2 = r'kya aaj kuch achha hoga'\n",
    "   a2 = ['haan','mujhe kya pata','mein kyo batau']\n",
    "   qa_pair = [\n",
    "        [q1,a1],\n",
    "        [q2,a2],\n",
    "    ]\n",
    "   cb = Chat(qa_pair)\n",
    "   tts = pyttsx3.init()\n",
    "   rec = sr.Recognizer()\n",
    "   while True:\n",
    "        with sr.Microphone() as mic:\n",
    "            print('Speak:')\n",
    "            audio = rec.listen(mic,phrase_time_limit=3,timeout=5)\n",
    "            try:\n",
    "               text = rec.recognize_google(audio).lower()\n",
    "               print(text)\n",
    "               if flag == True:\n",
    "                    if 'search' in text:\n",
    "                        item = text.split('search')[-1].strip()\n",
    "                        flipkart_url = 'https://flipkart.com/search?q='\n",
    "                        amazon_url = 'https://amazon.in/s?k='\n",
    "                        web.open_new(flipkart_url + item)\n",
    "                        web.open_new_tab(amazon_url + item)\n",
    "                    else:\n",
    "                        resp = cb.respond(text)\n",
    "                        if resp == None:\n",
    "                            tts.say('Sorry, I dont know')\n",
    "                        else:\n",
    "                            tts.say(resp)\n",
    "                        tts.runAndWait()\n",
    "                    flag = False\n",
    "               if 'hey google' in text:\n",
    "                    flag = True\n",
    "               elif 'mar ja' in text: \n",
    "                    break\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
